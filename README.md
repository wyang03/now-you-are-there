# now you are there when this happened

## short description
The project focuses on time and memory, building on previous projects both thematically and technically. It involves audio, visual, and interactive elements inspired by various memory models. One model explored is episodic memory vs semantic memory, with the recording of a previous musical performance representing episodic memory and serving as an invitation to unlock semantic memory. Another model is the tri-part construct of sensory memory, short-term memory, and long-term memory. The project also explores the impact of spatial sounds on memory encoding and uses scattered instruments and visual effects to create a memorable experience. A particle system provides dynamic interaction and connects visual and audio elements. Additionally, a video delay line creates ghostly copies of viewers for interactive engagement.

## detailed description
As the title suggests, it deals again with time and memory – an extension from the previous two projects both thematically and technically. There are several components in this project, the audio, the visual, and the interactivity, and the way they are implemented are informed and inspired by various models of memory. These theories/models of memory are not always clearly mapped to certain elements of the work, but they were integral in decision-making. 

The first type of memory model explored is **episodic memory** vs **semantic memory**. When you walk into it, the most obvious element is the recording of Murphy’s playing projected onto the screen, which was taken from the performance of a previous project. This is a very specific event, or as one might call it, an episodic memory. What it does is point to a specific context (a musical performance) and encourage the retrieval of certain sets of knowledge and expectations that are usually associated with this type of context. This serves as the invitation to unlock what is often called semantic memory, which is the beginning of the construction or reconstruction process. 

Another type of memory model that was explored was **the tri-part construct of sensory memory, short-term memory, and long-term memory**. They are not organized linearly but rather intermingle with each other at different stages. I was particularly drawn to the sensory memory, which takes place in the initial memory encoding stage. There have been studies made to prove that phonological information is crucial for memory encoding, as well as for recalling that memory at a later time. For example, if you witness an event accompanied by some salient sounds, you are more likely to remember it better and faster than simply witnessing it without the sounds. To explore this idea, we tried two things. One is to superimpose sounds of different spatial information – we have Murphy’s playing, which is rather spacious sounding, and there is the breathing sound, which is much more intimate, and there is also a very dry clicky sound, which sounds almost like right next to you. By putting these sounds together, the spatial discrepancy became salient enough so that memory encoding happens effectively. 

We also scattered different instruments across the room, including the drum set, but also some small percussions, either on the floor or suspended. Visually speaking, the drum set and the percussions are the remanence of what was in the video, and it can help with setting up context. Another reason is that so when you are in the space, it can be difficult to move around without making sounds, and again we hope this will result in remembering this experience better. Another visual component is the particle system, which is the more mobile version of the video playback, the sound, and the staging of the instruments - it does what I want the static components to do, but dynamically. It is the main interface for interaction. Superficially, there is this mental image of a memory being stored in some place, like a vase, and collecting dust, so the particles seem to be a nice choice. It also connects the visual to the audio – the particles are attracted to the moving subjects in real-time and depending on the number of particles moving and their general velocity, sounds are triggered, and added to the existing sound world. Finally, I want it to provide the opportunity to rewrite the memory if one is after a more conscious reconstructive approach. 

One more thing in the video was there is a video delay line. They don’t always show up at the same time at the same strength, but at some point, you see there is a current version of you in a kind of wireframed mesh, and there are two other copies of you in a ghostly manner, the closer you get to the projected video, the more visible they are, and one of them is a delayed version. For example, if you walk around, you might notice there is a delayed copy of you, you can just look at this memory of you, or you can interact with it!


